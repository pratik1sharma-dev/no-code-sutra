# LLM Provider Configuration
# Choose one of the following options:

# Option 1: Amazon Bedrock (Fastest & Most Reliable) - RECOMMENDED
AWS_BEARER_TOKEN_BEDROCK=your_bedrock_bearer_token_here
AWS_DEFAULT_REGION=ap-southeast-1
BEDROCK_MODEL_ID=meta.llama3-1-8b-instruct-v1:0

# Option 2: Ollama (Local, Free)
# USE_OLLAMA=true
# OLLAMA_MODEL=llama3.1

# Option 3: Hugging Face (Free tier)
# HUGGINGFACE_API_TOKEN=your_hf_token_here
# HF_MODEL_ID=meta-llama/Llama-3.1-8B-Instruct

# Option 4: Together AI (Very cheap - $0.20 per 1M tokens)
# TOGETHER_API_KEY=your_together_api_key_here

# Option 5: OpenAI (Expensive - fallback only)
# OPENAI_API_KEY=your_openai_api_key_here

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=true 